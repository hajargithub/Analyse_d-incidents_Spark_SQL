# TP3 â€” Spark SQL : Analyse dâ€™incidents (local & cluster Docker)

Ce projet **Maven + Java (Spark SQL)** lit un CSV dâ€™incidents et produitÂ :
1) **Le nombre dâ€™incidents par service**
2) **Les deux annÃ©es** oÃ¹ il y avait **le plus dâ€™incidents**

Format CSV attenduÂ : `id,titre,description,service,date`

Exemple dans [`data/incidents.csv`](data/incidents.csv).

---

## ğŸ§± Architecture & modes dâ€™exÃ©cution

### 1) ExÃ©cution locale (dÃ©veloppement / test)
- **Driver & executors** tournent dans **le mÃªme JVM** sur votre machine.
- Master configurÃ© en **`local[*]`** (dans le code) â†’ simple Ã  lancer depuis IntelliJ.
- Lecture/Ã©criture sur le **systÃ¨me de fichiers local** (ex. `data/`, `output/`).

```
[Votre PC]  Driver + Executors (local[*])
       â†˜ lit data/incidents.csv
       â†˜ Ã©crit output/{incidents_by_service, top_years}
```

### 2) ExÃ©cution sur cluster Spark (Docker Standalone)
- Un **Master** + un (ou plusieurs) **Workers** dans des **conteneurs**.
- Vous soumettez lâ€™application avec **`spark-submit`** (driver cÃ´tÃ© master).
- Les **donnÃ©es & le JAR** doivent Ãªtre **accessibles par tous les nÅ“uds** â†’ on utilise un **volume partagÃ©** `./shared` montÃ© en `/shared`.

```
[Host Docker]
  â””â”€ docker-compose (spark-master, spark-worker-1)
        â”œâ”€ Volume partagÃ©: ./shared â†” /shared
        â””â”€ spark-submit (Driver sur master) â†’ Executors sur worker(s)
```

Pourquoi ce designÂ ?
- **Local** : rapiditÃ© de test et itÃ©ration.
- **Cluster** : exÃ©cution distribuÃ©e, montÃ©e en charge, proche de la prod.

---

## ğŸ› ï¸ PrÃ©requis

- **Java 17+**
- **Maven 3.8+**
- **IntelliJ IDEA** (Community suffit)
- **Docker + docker-compose** (pour le mode cluster)

---

## ğŸ“¦ Ouverture du projet dans IntelliJ

1. `File` â†’ `Openâ€¦` â†’ sÃ©lectionnez le dossier **`incidents-spark-sql`**.
2. Laissez IntelliJ importer le projet **Maven**.
3. Ouvrez la classe **`IncidentsApp`** (`src/main/java/.../IncidentsApp.java`).

### â–¶ï¸ Lancer en local (IntelliJ)
- Clic droit sur `IncidentsApp` â†’ **Run 'IncidentsApp.main()'**
- Par dÃ©faut, le programme lit **`data/incidents.csv`** et Ã©crit dans **`output/`**.
- Vous pouvez aussi **passer des arguments**Â :
  - **Arg 0** : chemin CSV (ex. `data/incidents.csv`)
  - **Arg 1** : dossier de sortie (ex. `output`)

Exemple (Run configuration â†’ Program arguments)Â :
```
data/incidents.csv output
```

---

---
### ğŸ“· Captures

![Le nombre dâ€™incidents par service](Captures/Nombre%20d'incidents%20par%20service.PNG)

![Les deux annÃ©es** oÃ¹ il y avait **le plus dâ€™incidents](Captures/Top%202%20annÃ©es%20avec%20le%20plus%20d'incidents.PNG)
---

## ğŸ³ ExÃ©cution sur un cluster Spark (Docker)

### 1) DÃ©marrer le cluster
```bash
docker compose up -d
# UI Master: http://localhost:8080
# UI Worker:  http://localhost:8081
```

### 2) Construire le JAR
```bash
mvn -q -DskipTests package
# Produit: target/incidents-spark-sql-1.0.0.jar
```

### 3) PrÃ©parer donnÃ©es & JAR pour le cluster
Copiez le CSV et le JAR dans le **dossier partagÃ©** :
```bash
cp data/incidents.csv shared/incidents.csv
cp target/incidents-spark-sql-1.0.0.jar shared/app.jar
```

### 4) Soumettre le job depuis le Master
```bash
docker exec -it incidents-spark-master bash -lc "
  /opt/bitnami/spark/bin/spark-submit     --master spark://spark-master:7077     --class ma.enset.incidents.IncidentsApp     /shared/app.jar     /shared/incidents.csv     /shared/output
"
```

RÃ©sultats Ã©crits dans `shared/output/{incidents_by_service,top_years}` (fichiers CSV).

---

## ğŸ§ª Jeu de donnÃ©es dâ€™exemple

Un petit CSV est fourni dans `data/incidents.csv`. Vous pouvez le remplacer par vos donnÃ©es rÃ©elles, tant que lâ€™ordre des colonnes suit :

```
id,titre,description,service,date
```

> **Note sur la date** : lâ€™annÃ©e est extraite de maniÃ¨re robuste via une regex (`\d{4}`), ce qui supporte des formats comme `2024-03-30`, `30/03/2024`, etc.

---

## ğŸ§¾ Sorties attendues

- **`incidents_by_service`** : deux colonnes `service, nb_incidents`
- **`top_years`** : deux colonnes `year, nb_incidents` (top 2)

Les deux sont Ã©crites en **CSV** avec lâ€™option `header=true`.

---

### ğŸ“· Captures
![output_spark-cluster](Captures/Spark_cluster_output.PNG)


---

## ğŸ“š Stack technique

- **Spark** `${spark.version}` (Spark SQL)
- **Java 17**, **Maven**
- **Docker** (images Bitnami Spark)
- **Mode local** (`local[*]`) & **Standalone cluster** (`spark://spark-master:7077`)

Bon TPÂ ! ğŸš€
